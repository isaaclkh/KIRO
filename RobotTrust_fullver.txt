<ROBOT TRUST>

A Meta-Analysis of Factors Affecting Trust in Human-Robot Interaction
날짜 : 2011
url : https://apps.dtic.mil/sti/pdfs/ADA553574.pdf
요약 : 인간-로봇 상호작용(HRI)에서 인간, 로봇, 환경 요소가 신뢰에 미치는 영향을 평가하는 양적인 연구를 수행했습니다. 29개의 연구를 분석하여 10개는 상관 분석에, 11개는 실험 분석에 적합한 것으로 선정했습니다. 연구 결과로는 신뢰에 대한 상관 효과 크기가 r̄ = +0.26이었고, 실험 효과 크기는 d̄ = +0.71이었습니다. 로봇의 성능과 속성이 HRI에서 신뢰 형성에 가장 큰 영향을 미쳤으며, 환경 요소는 중간 정도의 역할을 했습니다. 인간과 관련된 요인은 거의 영향을 미치지 않았습니다. 이러한 결과는 로봇 디자인과 훈련 가이드라인 수립에 유용한 정보를 제공하며, 신뢰 캘리브레이션 문제를 로봇 디자인 조작을 통해 해결할 수 있음을 시사합니다. 그러나 미래 연구에 대한 필요성도 언급되었습니다.

Can You Trust Your Robot?
날짜 : 2011
url : https://peterhancock.ucf.edu/wp-content/uploads/sites/12/2012/05/Hancock_Billings-Ergonomics-in-Design-The-Quarterly-of-Human-Factors-Applications.pdf
요약 : 이 논문은 인간과 그들이 만드는 자동화 및 로봇 기술 간의 상호작용 관계에서 신뢰가 중요한 요소라고 제안합니다. 이 논문은 (a) 왜 신뢰가 이러한 유형의 상호작용에 중요한 문제인지, (b) 인간-로봇 신뢰 문제의 발전에 대한 간단한 역사, 그리고 (c) 신뢰 문제에 중점을 둔 인간 요소/인체공학 전문가의 인간-로봇 시스템 설계에 대한 가이드라인을 제시합니다. 우리의 연구는 로봇이 단순한 도구에서 능동적이고 감각을 가진 팀원으로 진화함에 따라 신뢰를 지속적이고 동적인 차원으로 고려합니다.
(속임수와 신뢰의 관계에 대해서)

Trust in Robots: Challenges and Opportunities
날짜 : 2020
url : https://link.springer.com/article/10.1007/s43154-020-00029-y
신뢰 연구의 최신 동향은 로봇 공학자들에게 신뢰할 수 있는 로봇을 개발하기 위한 다양한 도구를 제공합니다. 그러나 현실적인 인간-로봇 상호작용(HRI) 환경에서의 신뢰에는 여전히 도전이 있습니다. 신뢰 측정, 로봇의 행동에 대한 보장(예: 사용자의 개인 정보와 관련하여), 그리고 풍부한 다차원 데이터 처리에 대한 문제가 여전히 존재합니다. 우리는 심리측정학, 신뢰할 수 있는 시스템, 로봇 윤리학 및 딥러닝과 같은 최근의 발전이 이러한 문제들에 대한 해결책을 제공할 수 있다고 조사하였습니다. 결론적으로, 우리는 이러한 방법론적 발전이 진정으로 자율적이고 신뢰할 수 있는 사회 로봇의 창조를 위한 길을 열 수 있다고 생각합니다.

How Can We Trust Robots
날짜 : 2018
url : https://web.eecs.umich.edu/~kuipers/papers/Kuipers-cacm-18.pdf
요약 : 신뢰는 사회의 성공적인 기능에 필수적입니다. 협력을 위해서는 신뢰가 필요하며, 이는 사회가 필요로하는 자원을 생산합니다. 도덕과 윤리를 포함한 사회 규범은 개인들이 신뢰할 수 있는 방식으로 행동하도록 장려하고 이기적인 결정을 피하도록 합니다. 로봇과 AI의 설계는 이러한 사회적 규범을 따라야 하지만 진정한 도덕적 주체가 되어야 하는 것은 아닙니다. 사회적 규범은 사회에 따라 다양하며, 로봇의 행동도 그에 따라 달라질 수 있습니다. 성공적인 설계를 위해 다양한 철학적 도덕 이론들의 측면을 결합해야 합니다. 기술적 연구는 복잡한 환경에서 신속한 도덕적 결정과 느린 심사적 평가를 조화롭게 수행하는 방법을 모색해야 합니다. 자율 주행 자동차는 신뢰할 수 있는 로봇의 대표적인 사례가 될 수 있으며, 일상적인 행동이 얼마나 신뢰할 수 있는지에 초점을 맞춰야 합니다.
(윤리적이고 믿을 수 있는 로봇을 만드는 것, 하이브리드 결정 구조, 3가지 주된 윤리적 이론, 기존에 연구된 로봇 윤리에 대하여, fractal boundaries, 피드백과 하이브리드 윤리적 추론 아키텍처의 시간 단위, 딜레마)

Human-robot interaction: developing trust in robots (짧은 논문)
날짜 : 2012
url : https://www.researchgate.net/profile/Peter-Hancock-2/publication/241623880_Human-robot_interaction_Developing_trust_in_robots/links/00b7d533186506bad5000000/Human-robot-interaction-Developing-trust-in-robots.pdf
요약 : 사람과 로봇의 상호작용에서 신뢰는 중요한 요소로 고려해야 하는데, 신뢰의 존재 여부는 그 상호작용의 최종 결과에 확실히 영향을 미칩니다. 다양한 운용 맥락에서 이 신뢰의 형성과 유지에 대해 구분하는 연구는 제한적입니다. 우리는 이전 연구에서 사람-로봇 신뢰의 이론적 및 경험적 기반 요소를 조사해왔습니다. 여기에서는 우리의 연구 프로그램을 기반으로 한 종합적인 인간-로봇 신뢰 모델의 개발에 대한 진전을 설명합니다.
(로봇은 언제나 100퍼센트로 아무런 결함 없이 가동되지 않는다. 그렇다면 결함이 있을 때는 신뢰도가 어떻게 변하는지, 어떻게 신뢰도를 극복해갈 수 있는지 등에 대한 답을 찾을 수 있을 것이다라고 얘기한다)

Effect of Robot Performance on Human–Robot Trust in Time-Critical Situations
날짜 : 2017
url : https://bpb-us-e1.wpmucdn.com/sites.psu.edu/dist/2/59794/files/2019/05/Effect-of-Robot-Performance-on-Human–Robot.pdf
요약 : 로봇은 비상 대피와 같은 고위험 상황에서 생명을 구할 수 있는 잠재력을 갖고 있습니다. 이러한 잠재력을 실현하기 위해서는 로봇의 성능, 상황의 위험성, 대피자의 동기 등과 같은 요소가 로봇을 따르는 결정에 어떻게 영향을 미치는지 이해해야 합니다. 본 논문에서는 가상 미로를 탐색하는 과제를 사용하여 대피 상황을 시뮬레이션하는 다양한 방법을 적용한 실험을 개발했습니다. 참가자들은 두 개의 별개의 탐색 라운드에서 로봇을 안내로 사용할지 여부를 선택했습니다. 로봇은 세 가지 조건 중 두 가지에서 성능이 좋지 않았습니다. 로봇의 성능이 좋지 않을 때 자기 신고된 신뢰도는 53% 감소했습니다. 자기 신고된 신뢰도는 로봇을 안내로 사용하는 결정과 강한 상관 관계가 있었습니다. 결론적으로, 로봇의 실수는 이후의 상호작용에서 사람들이 로봇에 대한 신뢰 수준을 현저하게 낮추게 합니다.

A Model of Human-Robot Trust: Theoretical Model Development
날짜 : 2011
url : https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=a708445dc08477392ef9b467faed6b24e47745b0
요약 : 이 연구는 신뢰의 이론적 기반을 탐구하며, 이는 인간-로봇 팀 신뢰 모델의 개발을 위한 프레임워크를 제공합니다. 이 모델의 실용적인 목적은 로봇 팀원에 대한 인간 운영자의 신뢰 형성을 촉진하는 요소를 보다 잘 이해하기 위한 것입니다. 우리는 완료한 양적 메타분석 결과를 바탕으로 모델의 구조를 예측합니다. 우리의 접근 방식은 인간-로봇 상호작용에서 신뢰에 영향을 미치는 차원을 분류합니다. 현재까지 우리는 인간, 로봇, 환경 기반 요소를 탐구했습니다. 모델의 개발과 정제를 위한 로드맵이 여기서 개요되어 있습니다.

Building Appropriate Trust in Human-Robot Teams
날짜 : 2013
url : https://cdn.aaai.org/ocs/5784/5784-24579-1-PB.pdf
요약 : 미래의 로봇 시스템은 도구에서 팀원으로 전환되어 자율성과 지능성이 높은 로봇이 더 자연스러운 방식으로 인간과 상호작용하며, 인간-인간 팀워크에 더 가까운 관계를 형성할 것으로 예상됩니다. 다른 시스템에서 관찰된 신뢰의 영향을 고려하면, 로봇 팀원에 대한 신뢰는 효과적이고 안전한 성과에 중요한 역할을 할 것입니다. 이 논문의 주장은 로봇 팀원에 대한 신뢰는 단순히 극대화되기보다 적절하게 조정되어야 한다는 것입니다. 우리는 인간 팀원의 시스템 이해가 인간-로봇 팀워크에서의 신뢰에 어떻게 기여하는지, 정신 모델 이론을 통해 설명합니다. 정신 모델은 로봇의 물리적 및 행동적 특성과 신뢰와 시스템의 사용/미사용/잘못 사용과 같은 감정적 및 행동적 결과와 관련이 있다고 논의합니다. 인간-로봇 팀 연구 및 설계와 인공 지능을 사용한 다른 시스템에 대한 모범 사례를 제시하여 이 논의를 확장합니다.
Building Trust in Artificial Intelligence, Machine Learning, and Robotics
날짜 : 2018
url : https://www.researchgate.net/profile/Keng-Siau-2/publication/324006061_Building_Trust_in_Artificial_Intelligence_Machine_Learning_and_Robotics/links/5ab8744baca2722b97cf9d33/Building-Trust-in-Artificial-Intelligence-Machine-Learning-and-Robotics.pdf
요약 : 이 논문에서는 인공지능, 기계학습(ML) 및 로봇에 대한 신뢰를 살펴봅니다. 먼저 인공지능에 대한 신뢰의 개념을 검토하고, 다른 기술에 대한 신뢰와는 어떻게 다를 수 있는지 살펴봅니다. 그런 다음 인간 간 신뢰와 기술에 대한 신뢰 사이의 차이를 논의하고, 인공지능에 대한 초기 신뢰를 구축하고 지속적인 신뢰를 발전시키는 데 중요한 요소를 제안합니다.

Human–robot collaboration in industrial applications: Safety, interaction and trust
날짜 : 2017
url : https://journals.sagepub.com/doi/full/10.1177/1729881417716010
요약 : 인간-로봇 협업은 미래의 공장 개발에 있어 핵심 요소로 작용하며, 인간과 로봇이 함께 작업하고 과업을 수행할 수 있는 공간을 의미합니다. 이러한 협업적인 인간-로봇 패러다임에서 안전은 가장 중요한 측면 중 하나입니다. 이 논문은 FourByThree 프로젝트의 저자들이 산업용 로봇 응용 분야에서 울타리 없는 인간-로봇 협업의 신뢰를 측정하고 로봇과 인간 간의 다양한 상호작용 메커니즘의 수용성을 평가하기 위해 수행한 실험과 그 결과를 설명합니다.

Do travelers trust intelligent service robots?
날짜 : 2020
url : https://www.sciencedirect.com/science/article/pii/S016073832030030X?casa_token=YCDS81xyq6EAAAAA:X7f5ncMUrJ4X10rIJ4oPlsLYSwZpxiKm-gNyhxIU8dZmnWjAmjhYTjGIRlmy0TQHu6-wePZUyKU
요약 : 이 연구는 자율 주행 교통 및 로봇 바텐더를 대상으로 한 두 가지 연구를 통해 여행자들의 지능형 자율 기술에 대한 신뢰를 조사합니다. 미국에 거주하는 여행자들을 대상으로 온라인 설문조사를 실시하여 지능형 로봇에 대한 신뢰와 그 선행요인, 결과와의 관계를 검증하였습니다. 결과는 지능형 로봇이 신뢰의 대상인 상황에서 인지적 신뢰 형성 과정이 적용됨을 보여줍니다. 지능형 기계에 대한 신뢰는 기술에 대한 부정적 태도와 기술에 대한 신뢰성 경향에 영향을 받습니다. 놀랍게도 로봇의 물리적 형태는 신뢰에 영향을 주지 않습니다. 마지막으로, 신뢰는 두 연구 모두에서 채택 의도로 이어집니다. 이 연구의 기여는 여행 환경에서 사회적 상호작용을 위해 설계된 지능형 로봇에 대한 소비자의 신뢰를 명확히 하는 데 있습니다.

—
Human-Robot Interaction: Developing Trust in Robots
년도 : 2012
url : https://www.researchgate.net/profile/Peter-Hancock-2/publication/241623880_Human-robot_interaction_Developing_trust_in_robots/links/00b7d533186506bad5000000/Human-robot-interaction-Developing-trust-in-robots.pdf
요약 : 모든 인간-로봇 상호작용에서 신뢰는 고려해야 할 중요한 요소입니다. 왜냐하면 신뢰의 존재 또는 부재는 상호작용의 최종 결과에 확실히 영향을 미치기 때문입니다. 다양한 운용 맥락에서 이 신뢰의 발전과 유지에 대한 연구는 제한적입니다. 이전 연구에서는 이론적으로와 경험적으로 지지되는 인간-로봇 신뢰의 선행 조건들을 조사해왔습니다. 여기에서는 우리의 계속되는 연구 프로그램에 기반한 포괄적인 인간-로봇 신뢰 모델의 개발에 대한 최신 진전 상황을 설명합니다.

Trust and cognitive load during human-robot interaction
년도 : 2019
url : https://arxiv.org/pdf/1909.05160.pdf
요약 : 결과적으로 우리는 신뢰와 인지적 부하 사이에 역비례 관계가 있음을 발견했습니다. 이는 참가자들이 인지적 부하가 증가함에 따라 신뢰도 평가가 감소하는 것을 시사합니다. 또한 로봇 유형, 오류율 및 참가자의 신뢰도 평가 사이에 삼중 상호작용 영향을 발견했습니다. 높은 오류율 조건에서 두 로봇과 함께 게임을 한 후 참가자들은 Pepper를 Husky 로봇보다 더 신뢰할 것으로 인식했습니다. 그러나 낮은 오류율로 설정된 경우, Husky가 Pepper보다 더 신뢰할 것으로 인식되었습니다. 우리의 결과는 물리적 의인화와 변수 오류율의 조합이 어떻게 영향을 미치는지에 대한 추가적인 조사를 요구합니다.

The Perception And Measurement Of Human-robot Trust
년도 : 2013
url : https://stars.library.ucf.edu/cgi/viewcontent.cgi?article=3688&=&context=etd&=&sei-redir=1&referer=https%253A%252F%252Fscholar.google.com%252Fscholar%253Fhl%253Den%2526as_sdt%253D0%25252C5%2526q%253Dhuman%252Brobot%252Btrust%2526oq%253Drobot%252Btrust#search=%22human%20robot%20trust%22
요약 : 사람과 로봇의 신뢰 척도 개발을 하기 위하여 연구하였음. 중간에 신뢰 모델을 설명하면서 신뢰의 요인들을 설명하는 부분이 있음 (Chapter 2). 로봇의 기능과 환경이 신뢰에 미치는 영향들을 소개하며 신뢰를 쌓을 수 있는 요인들을 소개함.

Planning with trust for human-robot collaboration
년도 : 2018
url : https://par.nsf.gov/servlets/purl/10066121
요약 : 이 논문은 신뢰를 로봇의 의사 결정에 통합하는 계산 모델을 소개합니다. 구체적으로, 우리는 인간 신뢰를 잠재 변수로 하는 부분 관찰 가능한 마르코프 의사 결정 과정 (POMDP)를 데이터로부터 학습합니다. 이 신뢰-POMDP 모델은 로봇이 (i) 상호작용을 통해 인간 팀원의 신뢰를 추론하고, (ii) 자신의 동작이 인간 행동에 미치는 영향을 추론하며, (iii) 장기적으로 팀 성능을 극대화하는 동작을 선택하는 데 사용하는 원칙적인 접근 방식을 제공합니다. 우리는 이 모델을 시뮬레이션에서 (201명의 참가자) 및 실제 로봇을 통해 (20명의 참가자) 테이블 청소 작업에서 인간 실험을 통해 검증하였습니다.
결과는 이 신뢰-POMDP가 이 작업에서 인간-로봇 팀 성능을 향상시킨다는 것을 보여줍니다. 더 나아가, 신뢰를 극대화하는 것 자체가 팀 성능을 향상시키지 않을 수도 있다는 것을 시사합니다.

Modeling Trust in Human-Robot Interaction : A Survey
년도 : 2020
url : https://arxiv.org/pdf/2011.04796.pdf
요약 : HRI에서 신뢰를 조정하기 위해선 먼저 신뢰가 모델링되어야 합니다. HRI에서 신뢰에 영향을 미치는 요소에 대한 많은 리뷰가 있지만, 다양한 신뢰 모델에 중점을 두는 리뷰는 없기 때문에 이 논문에서는 HRI에서 신뢰 모델링을 위한 다양한 기술과 방법을 검토합니다. 또한 미래의 인간-로봇 신뢰 모델링 연구에 대한 추가 연구 방향과 해결해야 할 일부 과제를 제시합니다. (factors affecting trust도 소개하고 있음)

Human-Robot Interaction: Proximity and Speed—Slowly Back Away from the Robot!
년도 : 2017
url : https://d1wqtxts1xzle7.cloudfront.net/85518580/macarthur-et-al-2017-proximity-and-speed-libre.pdf?1651743699=&response-content-disposition=inline%3B+filename%3DHuman_Robot_Interaction_Proximity_and_Sp.pdf&Expires=1694070150&Signature=T6XFewKldmtKjkP6i2-lCdLq2jv~i4hVeNw6MUoHTk65sVwOugK4zqvJnri18ZntSgALKDWqefXpVy9tAQZLKB9f0Hh7aF8XIbsoUzglLjRgLyT0uuafqDC~ycSEsloOacSBSzHvJOi6kx6qZwDKuWG4HKQwHQsljiNAjQvIrXHtaJjlubUSd1MDVIMsH831qq2iU1in0ok-vA8WmDBR0635Bc6RbtWPgUrDB0j5z3icLNG-vuC8GXFXWuLJ-Z6unjjRRW-B4l9SL05PuqwfgcY8xu02nxGbJz0rgDR9v67n-DZBUGWN9xvi3jY4nO4tHpaIImTaP38~9GI23bHWMg__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA
요약 : 설문 조사는 일반적인 관행에 따라 점수가 매겨졌으며, 조건(빠른 근접, 빠른 거리, 느린 근접, 느린 거리)을 내부 주체 요인으로 사용한 혼합설계 분산분석(ANOVA)가 실시되었습니다. 분석 결과, 근접성이 신뢰 점수의 변화에 기여하는 중요한 요인으로 나타났습니다 [F(2, 146) = 6.842, p < 0.01, 부분 ŋ2 = 0.086]. 이러한 결과는 Human-Robot Trust Scale(F = 13.212, p < 0.001, 부분 ŋ2 = 0.082) 및 Trust in Automation Scale(F = 11.099, p = 0.001, 부분 ŋ2 = 0.07)에서 관찰되었습니다. 따라서 우리의 가설이 지지되었습니다. 근접성 (근접-멀음)의 Bonferroni 수정된 쌍별 비교는 Human Robot Trust Scale에서 평균 차이가 -4.73이고, Trust in Automation Scale에서 평균 차이가 -0.19임을 나타냈습니다. 이것은 로봇이 참가자로부터 더 멀리 있는 조건에서 참가자들이 더 높은 신뢰 점수를 평가했음을 나타내며, 우리의 두 번째 가설을 지원합니다.

제목 : Trust and Cognitive Load During Human-Robot Interaction
년도 : 2019
url : https://arxiv.org/pdf/1909.05160.pdf
본 논문은 인간의 인지 부하, 신뢰, 및 인간화와의 관계를 이해하기 위한 탐색적 연구를 제시합니다. 이 관계를 이해하기 위해 "쌍 맞추기" 게임을 만들어 참가자들이 두 가지 로봇 유형 중 하나인 Husky 또는 Pepper와 협력하여 플레이할 수 있도록 하였습니다. 목표는 참가자들이 높은 수준의 인지 부하를 요구하는 게임 플레이 상황에서 로봇을 팀원으로 신뢰할 것인지를 이해하는 것이었습니다. 인간형 로봇 대 기술적 로봇을 사용하여 신체적 인간화의 영향을 조사하였으며, 로봇 오류율이 후속 판단과 행동에 미치는 영향도 테스트하였습니다. 결과는 신뢰와 인지 부하 사이에 역비례 관계가 있음을 보여주어, 참가자들의 인지 부하 양이 증가할수록 그들의 신뢰 점수가 감소한다는 것을 시사했습니다. 또한 로봇 유형, 오류율 및 참가자의 신뢰 점수 사이에 삼중 상호작용의 영향을 발견했습니다. 우리는 참가자들이 고장율이 높은 조건에서 두 로봇과 게임을 한 후에 Pepper를 Husky 로봇보다 더 신뢰한다고 인식했다는 것을 발견했습니다. 반면, Husky는 낮은 오류율로 묘사될 때 Pepper보다 더 신뢰할 만하다고 인식되었습니다. 이러한 결과는 로봇의 신체적 인간화와 다양한 오류율의 조합이 미치는 영향을 더 자세히 조사할 필요가 있음을 시사합니다.

제목 : When Would You Trust a Robot? A Study on Trust and Theory of Mind in Human-Robot Interactions
년도 : 2021
url : https://arxiv.org/pdf/2101.10819.pdf
요약 : 신뢰는 인간-로봇 상호작용(HRI)에서 중요한 이슈로, 비인간 에이전트를 받아들이고 사용하기 위한 인간의 핵심 욕망입니다. 이론적 의식(ToM)은 다른 사람들의 신념과 의도를 이해하는 능력으로, 자신의 것과 다를 수 있는 다른 사람의 신념과 의도를 이해하는 것입니다. 심리학과 HRI의 증거들은 신뢰와 ToM이 서로 연관되고 상호의존적인 개념임을 시사합니다. 다른 에이전트를 신뢰하기 위한 결정은 이 엔티티의 행동, 신념 및 의도에 대한 자체 표현에 의존해야 하기 때문입니다. 그러나 HRI에서 신뢰를 연구하는 동안 로봇의 ToM을 고려하는 연구는 매우 적습니다. 본 논문에서는 로봇의 ToM 능력에 노출되는 것이 로봇에 대한 인간의 신뢰에 어떤 영향을 미칠 수 있는지 조사하였습니다. 이를 위해 참가자들은 ToM 능력이 낮은지 높은지로 소개된 인간형 로봇(페퍼)과 가격 게임을 플레이했습니다. 구체적으로 참가자들은 로봇이 제시한 일반 물건의 가격 평가를 받아들일 것인지 여부를 묻는 것이었습니다. 물건의 가격 판단을 바꿀 의향(로봇이 제안한 가격을 받아들일 것인지 여부)이 로봇에 대한 신뢰의 주요 측정 요소로 사용되었습니다. 실험 결과는 ToM 능력이 높은 로봇이 ToM 능력이 낮은 로봇보다 더 신뢰받았음을 보여주었습니다.

제목 : Designing for Trust
년도 : 2002
url : https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=e917142f1bea1d23ce6b1c7e62f0a91ecf5cd300
요약 : 신뢰를 위한 디자인은 신뢰가 어떤 미묘한 방식으로 시스템에 내재될 수 있는지를 식별하는 것을 요구합니다. 신뢰를 개인 정보, 보안 및 신뢰성의 교차점으로 정의하면 신뢰를 기술적 디자인에 내재화하거나 단순화할 수 있습니다. 그러나 이 정의는 단순화하는 동시에 가끔 간과되는 문제를 밝혀내기도 합니다. 개인 정보는 신뢰의 요소이기 때문에, 순수한 운영적 정의만으로는 인간들이 네트워크를 통해 신뢰를 확장할 수 있도록 시스템을 개발하는 데 부족합니다. 개인 정보는 데이터 공유를 통한 운영적 측면과 개인의 개인 정보에 대한 사용자 인식을 기반으로 한 내부적 측면 모두입니다. 다음 세대 인터넷을 위한 신뢰 메트릭스를 디자인하고, 신뢰를 내재화하는 디자인을 구현하기 위해서는 보안의 기술적 미묘성 뿐만 아니라 신뢰 인식의 인간적 미묘성을 이해하는 것이 필요합니다.


제목 : Robot transparency, trust and utility
년도 : 2016
url : https://www.tandfonline.com/doi/full/10.1080/09540091.2017.1313816
요약 : 
로봇의 추론이 더 복잡해짐에 따라 로봇 디자이너 및 기술 전문가에게도 관측 가능한 행동만을 기반으로 디버깅이 점점 어려워지고 있습니다. 마찬가지로, 비전문가 사용자는 로봇의 행동 관찰로부터 로봇 추론에 대한 유용한 정신적 모델을 생성하는 데 어려움을 겪고 있습니다. EPSRC 로봇 공학 원칙에 따르면 우리의 물건은 투명해야 하지만, 이것이 실제로는 무엇을 의미하며, 투명성이 신뢰와 유용성에 어떤 영향을 미치는지는 어떤지 조사합니다. 우리는 이 관계를 문헌에서 조사하고, 특히 산업용 환경이 아닌 환경에서는 어플리케이션과 로봇의 목적에 따라 투명성이 신뢰와 유용성에 다양한 영향을 미칠 수 있기 때문에 이것이 복잡하다는 것을 발견했습니다. 우리는 투명한 기계적 성격을 가진 투명한 에이전트를 생성하는 것이 가능하다는 주장을 지원하기 위한 연구 프로그램을 개요로 설명합니다. 이러한 에이전트는 투명성을 가지며 동시에 감정적으로 매력적일 수 있다는 주장을 지원하기 위한 연구 프로그램을 개요로 설명합니다.

제목: When Would You Trust a Robot? A Study on Trust and Theory of Mind in Human-Robot Interactions
년도 : 2021
url : https://arxiv.org/pdf/2101.10819.pdf
요약 :
신뢰는 인간-로봇 상호작용(HRI)에서 중요한 문제로, 비-인간 에이전트를 받아들이고 사용하는 인간의 핵심 욕망입니다. 이론적 관점에서, 타인의 신념과 의도를 이해하는 능력인 "마음의 이론" (ToM)은 자신의 것과 다를 수 있는 다른 사람들의 신념과 의도를 이해하는 능력으로 정의됩니다. 심리학과 HRI의 증거들은 신뢰와 ToM이 서로 연결되고 의존적인 개념이라고 제시하며, 다른 에이전트에 대한 신뢰 결정은 이 개체의 행동, 신념 및 의도에 대한 자체 표현에 의존해야 한다는 것을 나타냅니다. 그러나 매우 적은 연구가 HRI에서 신뢰를 연구하는 동안 로봇의 ToM을 고려합니다. 본 논문에서는 로봇의 ToM 능력에 노출이 로봇에 대한 인간의 신뢰에 영향을 미칠 수 있는지 조사했습니다. 이를 위해 참가자들은 로봇 (Pepper)과 함께 Price Game을 플레이했으며, 이 로봇은 낮은 수준의 ToM 또는 높은 수준의 ToM을 가진 것으로 제시되었습니다. 구체적으로 참가자들은 로봇이 제시하는 공통 물건의 가격 평가를 받아들일지 여부를 물었습니다. 참가자들이 자신의 물건의 가격 판단을 변경하기 원하는 정도(즉, 로봇이 제안한 가격을 받아들이는 정도)가 로봇에 대한 신뢰의 주요 측정 지표로 사용되었습니다. 실험 결과는 높은 수준의 ToM 능력을 가진 로봇들이 낮은 수준의 ToM 능력을 가진 로봇보다 더 신뢰받는다는 것을 보여주었습니다.

제목 : Enhancing Trust in Autonomous Vehicles through Intelligent User Interfaces That Mimic Human Behavior
년도 : 2018
url: https://www.mdpi.com/2414-4088/2/4/62
요약 : 
자율 주행 차량은 센서와 인공 지능을 사용하여 스스로 주행하는 기술입니다. 조사 결과에 따르면, 사람들은 자율 주행 아이디어에 놀라지만 차량 제어를 내주기를 망설이는 것으로 나타납니다. 이러한 우려의 핵심 원인은 신뢰 부족인 것으로 보입니다. 이를 해결하기 위해 인간적인 특성이 인터페이스에서 신뢰를 증가시킨다는 주장에 따라 지능형 에이전트 접근 방식이 구현되었습니다. 다른 접근 방식이 주로 외모를 형성하는 데 인간 형상화를 사용하는 데 비해 현재의 접근 방식은 그라이스 맥심 (즉, 효과적인 대화를 위한 지침)을 적용하여 상호작용을 형성하기 위해 인간 형상화를 사용합니다. 이 접근 방식의 기여도는 그래픽 및 대화형 사용자 인터페이스를 모두 사용한 시뮬레이터에서 평가되었으며, 이들은 호감도, 지능 인식, 신뢰 및 인간 형상화에 대한 등급을 받았습니다. 결과는 대화형 인터페이스가 그래픽 사용자 인터페이스보다 신뢰를 더 많이 받고 호감을 끌고 인간 형상화되며 더 똑똑하다고 인식되었음을 보여줍니다. 또한 결정을 내리는 데 있어 더 자신감 있는 인터페이스가 자신감이 낮은 인터페이스보다 네 가지 구성 요소에서 모두 더 높은 점수를 받았습니다. 이러한 결과는 자율 주행 차량에 인간 행동을 모방한 인터페이스를 제공하면 사람들의 신뢰와 따라서 수용을 높이는 데 도움이 될 수 있음을 나타냅니다.

제목 : Do Robot Performance and Behavioral Style affect Human Trust?
년도 : 2014
url : https://www.researchgate.net/profile/Pim-Haselager/publication/268331925_Do_Robot_Performance_and_Behavioral_Style_affect_Human_Trust_A_Multi-Method_Approach/links/55c88e3508aeca747d66e84c/Do-Robot-Performance-and-Behavioral-Style-affect-Human-Trust-A-Multi-Method-Approach.pdf
요약 : 
로봇의 사회적 행동의 중요한 측면 중 하나는 적절한 신뢰성을 전달하는 것입니다. 작업 수행이 신뢰성 판단에 중요한 정보원임이 밝혀졌습니다. 여기에서는 로봇의 행동 스타일과 같은 요인들이 중요한 역할을 할 수 있다고 주장합니다. 로봇의 성능과 행동 스타일이 인간의 신뢰에 미치는 영향을 연구하는 우리의 접근 방식은 비디오 인간-로봇 상호작용 (VHRI) 및 몰입형 가상환경 (IVE)에서 시뮬레이션된 로봇과의 실험을 포함합니다. VHRI 및 IVE 환경은 실제 로봇과의 진정한 상호작용을 대체할 수는 없지만, 사회적 인간-로봇 상호작용 분야의 실험적 연구에 유용한 보조적인 접근 방식을 제공할 수 있습니다. VHRI는 로봇 행동의 빠른 프로토타이핑을 가능하게 합니다. IVE에서 인간-로봇 상호작용을 시뮬레이션하는 것은 인간의 로봇에 대한 반응을 측정하는 유용한 도구이며, 실제 하드웨어로 인한 여러 제약 사항을 피하는 데 도움이 될 수 있습니다. 그러나 한 환경 (예: VHRI)에서 얻은 결과를 다른 환경 (예: IVE 또는 실제 세계)로 일반화하는 데 어려움이 있으며, 이에 대해 논의합니다. 이 논문에서는 VHRI에서 애니메이션 로봇 아바타를 사용하여 로봇 행동 스타일이 로봇에 대한 인간의 신뢰 평가에 어떤 영향을 미치는지 빠르게 확인합니다. 이후 연구에서는 VHRI 실험에서 얻은 행동을 갖춘 애니메이션 로봇 아바타와 인간 간의 행동 상호작용을 측정하기 위해 IVE를 사용합니다. 우리의 결과는 로봇의 작업 성능이 그 신뢰성에 영향을 미치지만, VHRI 연구에서 확인된 행동 스타일은 IVE 연구에서 로봇의 신뢰성에 영향을 미치지 않는 것을 재확인합니다.
